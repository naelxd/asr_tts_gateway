# Архитектурные решения и технические выборы

## Архитектура проекта

Проект состоит из **трёх независимых микросервисов** + клиента:

| Сервис          | Назначение                                                | Протокол                | Порт (в контейнере) |
| --------------- | --------------------------------------------------------- | ----------------------- | ------------------- |
| **tts-service** | Синтез речи (Text → Speech, streaming PCM)                | WebSocket (`/ws/tts`)   | `8082`              |
| **asr-service** | Распознавание речи (Speech → Text, offline)               | HTTP (`/api/stt/bytes`) | `8081`              |
| **gateway**     | Единая точка входа, проксирование и объединение пайплайна | WS + HTTP               | `8000`              |
| **client/**     | E2E-проверка работы пайплайна                             | CLI                     | —                   |

Сервисы связаны между собой внутри docker-сети `speech_net`.
Состояние (модели, логи) вынесено в именованные volume’ы:

* `models_asr:/opt/models`
* `models_tts:/opt/models`
* `logs:/var/log/app`

## Выбор моделей

### TTS: Coqui TTS + Tacotron2-DDC
**Выбор**: `tts_models/en/ljspeech/tacotron2-DDC`

**Анализ альтернатив**:
- **Piper**: Быстрее (C++), но сложнее в Docker, требует внешних зависимостей
- **Edge-TTS**: Проще интеграция, но хуже качество, требует интернет
- **gTTS**: Онлайн-сервис, не подходит для offline
- **Coqui TTS**: Оптимальный баланс качества, скорости и простоты интеграции

**Преимущества выбора**:
- Чисто Python (легкая Docker-интеграция)
- Хорошее качество на CPU
- Автоматический ресемплинг до 16kHz
- Простая интеграция с FastAPI
- Fallback на синусоиду при ошибках

### ASR: Faster-Whisper + Tiny.en
**Выбор**: `faster-whisper` с моделью `tiny.en`

**Анализ альтернатив**:
- **Whisper (оригинал)**: Лучше качество, но медленнее в 2-3 раза
- **SpeechRecognition**: Проще, но значительно хуже точность
- **DeepSpeech**: Быстрее, но устаревшая архитектура
- **Faster-Whisper**: Оптимизированная версия Whisper с минимальными потерями качества

**Преимущества выбора**:
- Скорость в 2-3 раза выше оригинального Whisper
- CPU-оптимизация с int8 квантованием
- Модель `tiny.en` - 39MB, быстрая загрузка
- Простой API без сложной конфигурации

## Технические сложности и решения

### Сложность 1: Проксирование WebSocket через Gateway
**Проблема**: Gateway должен проксировать WebSocket соединения к TTS сервису

**Решение**:
- `asyncio.gather()` для параллельной пересылки
- Обработка исключений с корректным закрытием соединений
- Передача сигнала `{"type": "end"}` от TTS к клиенту
- Graceful shutdown при ошибках

**Сложности**:
- Синхронизация двух WebSocket соединений
- Обработка разрывов соединений
- Корректная передача бинарных данных

### Сложность 2: Обработка PCM аудио данных
**Проблема**: Разные форматы аудио между сервисами

**Решение**:
- Унифицированный формат: PCM s16le mono 16kHz
- Валидация входных данных
- Ограничение длины аудио (15 сек для ASR)

**Технические детали**:
- Конвертация float32 → int16 с clipping
- Ресемплинг при необходимости
- Обработка моно/стерео входов

### Сложность 3: Управление большими моделями
**Проблема**: TTS модели весят 100+ MB, медленная загрузка

**Решение**:
- Lazy loading моделей при первом запросе
- Fallback на синусоиду при ошибках загрузки
- Кэширование загруженных моделей

**Альтернативы**:
- Pre-loading: Быстрее первый запрос, но больше памяти
- Model serving: Отдельный сервис для моделей
- Quantization: Меньший размер, но хуже качество


## Известные ограничения

| Область            | Ограничение                                              | Возможное решение                                          |
| ------------------ | -------------------------------------------------------- | ---------------------------------------------------------- |
| Производительность | CPU-инференс → возможна задержка при длинных текстах     | Использовать чанковую генерацию или GPU                    |
| Языки              | Только английский                                        | Подключить многоязычные модели (`small`, `base`, `medium`) |
| HTTP TTS           | Не реализован (используется WS-вариант)                  | Добавить HTTP `/api/tts` c `StreamingResponse`             |
| Ошибки сети        | При обрыве соединений возможно отсутствие явного статуса | Добавить явные WS error-ответы                             |
| Асинхронность      | Gateway использует `requests` (синхронный)               | Перевести на `httpx.AsyncClient`                           |
| CI/CD              | Нет GitHub Actions                                       | Добавить `pytest` + `ruff` в workflow                      |

